import { RefObject, useEffect, useRef, useState } from "react";
import "./App.css";
import * as handPoseDetection from "@tensorflow-models/hand-pose-detection";
import * as faceLandmarksDetection from "@tensorflow-models/face-landmarks-detection";
import * as poseDetection from "@tensorflow-models/pose-detection";
import * as tf from "@tensorflow/tfjs-core";
import "@tensorflow/tfjs-backend-webgl";

// ã‚¢ãƒ—ãƒªèµ·å‹•æ™‚ã«TensorFlow.jsã®ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚’åˆæœŸåŒ–
tf.setBackend('webgl').then(() => {
	console.log('TensorFlow.js backend initialized:', tf.getBackend());
}).catch(err => {
	console.error('Failed to initialize TensorFlow.js backend:', err);
});

type TabType = "hand" | "face" | "pose";

const useVideo = (
	videoRef: RefObject<HTMLVideoElement>,
	videoFile: File | null
) => {
	const [isAllowed, setIsAllowed] = useState(false);
	const [isVideoReady, setIsVideoReady] = useState(false);

	// ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚ŒãŸå ´åˆã®å‡¦ç†
	useEffect(() => {
		if (videoFile && videoRef.current) {
			console.log("å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ãŒé¸æŠã•ã‚Œã¾ã—ãŸ:", videoFile.name);
			
			// ã‚«ãƒ¡ãƒ©ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢
			const mediaStream = videoRef.current.srcObject as MediaStream;
			if (mediaStream) {
				mediaStream.getTracks().forEach(track => {
					track.stop();
					console.log("ã‚«ãƒ¡ãƒ©ãƒˆãƒ©ãƒƒã‚¯åœæ­¢:", track.kind);
				});
			}

			// å‹•ç”»ã®æº–å‚™çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
			setIsVideoReady(false);

			try {
				// ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®å‹•ç”»ã‚’è¨­å®š
				const fileURL = URL.createObjectURL(videoFile);
				console.log("å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«URL:", fileURL);
				
				// videoè¦ç´ ã‚’ãƒªã‚»ãƒƒãƒˆ
				videoRef.current.pause();
				videoRef.current.removeAttribute('srcObject');
				videoRef.current.srcObject = null;
				videoRef.current.src = fileURL;
				videoRef.current.muted = false;
				videoRef.current.crossOrigin = "anonymous";
				videoRef.current.load();
				
				console.log("å‹•ç”»è¦ç´ è¨­å®šå®Œäº†");
				
				// ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚ŒãŸã‚‰æº–å‚™å®Œäº†ã¨ãƒãƒ¼ã‚¯
				videoRef.current.onloadedmetadata = () => {
					console.log("å‹•ç”»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†:", videoRef.current?.videoWidth, "x", videoRef.current?.videoHeight);
					
					// ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚ŒãŸå¾Œã€å®Ÿéš›ã®å†ç”Ÿé–‹å§‹
					videoRef.current?.play().then(() => {
						console.log("å‹•ç”»å†ç”Ÿé–‹å§‹");
						setIsVideoReady(true);
					}).catch(err => {
						console.error("å‹•ç”»å†ç”Ÿã‚¨ãƒ©ãƒ¼:", err);
					});
				};
				
				// å†ç”Ÿçµ‚äº†æ™‚ã«ãƒ«ãƒ¼ãƒ—å†ç”Ÿ
				videoRef.current.onended = () => {
					console.log("å‹•ç”»å†ç”Ÿçµ‚äº†ã€ãƒ«ãƒ¼ãƒ—ã—ã¾ã™");
					if (videoRef.current) {
						videoRef.current.currentTime = 0;
						videoRef.current.play().catch(err => {
							console.error("å‹•ç”»ãƒ«ãƒ¼ãƒ—å†ç”Ÿã‚¨ãƒ©ãƒ¼:", err);
						});
					}
				};
				
				// ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
				videoRef.current.onerror = (e) => {
					console.error("å‹•ç”»èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼:", e);
				};
				
				setIsAllowed(true);
			} catch (error) {
				console.error("å‹•ç”»è¨­å®šã‚¨ãƒ©ãƒ¼:", error);
			}
			
			// ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
			return () => {
				if (videoRef.current) {
					const oldSrc = videoRef.current.src;
					videoRef.current.onloadedmetadata = null;
					videoRef.current.onended = null;
					videoRef.current.onerror = null;
					videoRef.current.pause();
					videoRef.current.src = "";
					videoRef.current.load();
					if (oldSrc) {
						URL.revokeObjectURL(oldSrc);
					}
					console.log("å‹•ç”»ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾");
				}
				setIsVideoReady(false);
			};
		} else if (!videoFile) {
			// ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆã¯ã‚«ãƒ¡ãƒ©ã‚’ä½¿ç”¨
			const setupCamera = async () => {
				if (!videoRef.current) return;
				try {
					if (navigator.mediaDevices.getUserMedia) {
						const stream = await navigator.mediaDevices.getUserMedia({
							video: true,
						});
						videoRef.current.srcObject = stream;
						videoRef.current.muted = true; // ã‚«ãƒ¡ãƒ©æ˜ åƒã¯ãƒŸãƒ¥ãƒ¼ãƒˆ
						
						// ã‚«ãƒ¡ãƒ©ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã¾ã‚ŒãŸã‚‰æº–å‚™å®Œäº†ã¨ãƒãƒ¼ã‚¯
						videoRef.current.onloadedmetadata = () => {
							console.log("ã‚«ãƒ¡ãƒ©æ˜ åƒãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†");
							setIsVideoReady(true);
						};
					}
					setIsAllowed(true);
				} catch (err) {
					console.error("ã‚«ãƒ¡ãƒ©ã‚¢ã‚¯ã‚»ã‚¹ã‚¨ãƒ©ãƒ¼:", err);
					setIsAllowed(false);
				}
			};

			setupCamera();
			
			// ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
			return () => {
				if (videoRef.current) {
					videoRef.current.onloadedmetadata = null;
					videoRef.current.onloadeddata = null;
					if (videoRef.current.srcObject) {
						const mediaStream = videoRef.current.srcObject as MediaStream;
						mediaStream.getTracks().forEach(track => track.stop());
					}
				}
				setIsVideoReady(false);
			};
		}
	}, [videoRef, videoFile]);

	return {
		isAllowed,
		isVideoReady,
	}
};

const useHandpose = (
	videoRef: RefObject<HTMLVideoElement>,
	canvasRef: RefObject<HTMLCanvasElement>,
	isVideoReady: boolean,
) => {
	const [isLoading, setIsLoading] = useState(false);
	const [model, setModel] = useState<handPoseDetection.HandDetector>();

	useEffect(() => {
		const loadHandpose = async () => {
			try {
				// TensorFlowãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®æº–å‚™ã‚’ç¢ºèª
				await tf.ready();
				
				// MediaPipeHandsãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
				const model = handPoseDetection.SupportedModels.MediaPipeHands;
				const detectorConfig = {
					runtime: 'tfjs' as const,
					modelType: 'full' as const,
					maxHands: 2  // æœ€å¤§2ã¤ã®æ‰‹ã‚’æ¤œå‡º
				};
				const detector = await handPoseDetection.createDetector(
					model,
					detectorConfig
				);
				
				setModel(detector);
			} catch (error) {
				console.error("æ‰‹ã®æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼:", error);
			}
		};

		setIsLoading(true);
		loadHandpose().finally(() => {
			setIsLoading(false)
		});
	}, []);

	useEffect(() => {
		// æ¥ç¶šã™ã‚‹ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã®ãƒšã‚¢ï¼ˆéª¨æ ¼ã‚’æç”»ã™ã‚‹ãŸã‚ï¼‰
		const connections = [
			// è¦ªæŒ‡
			[0, 1], [1, 2], [2, 3], [3, 4],
			// äººå·®ã—æŒ‡
			[0, 5], [5, 6], [6, 7], [7, 8],
			// ä¸­æŒ‡
			[0, 9], [9, 10], [10, 11], [11, 12],
			// è–¬æŒ‡
			[0, 13], [13, 14], [14, 15], [15, 16],
			// å°æŒ‡
			[0, 17], [17, 18], [18, 19], [19, 20],
			// æ‰‹ã®ã²ã‚‰
			[0, 5], [5, 9], [9, 13], [13, 17], [0, 17]
		];

		const detect = async () => {
			if (!model) return;
			if (!videoRef.current) return;
			if (!isVideoReady) return; // å‹•ç”»ãŒæº–å‚™ã§ãã¦ã„ãªã‘ã‚Œã°æ¤œå‡ºã—ãªã„
			
			try {
				// å‹•ç”»ã®ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
				if (videoRef.current.videoWidth === 0 || videoRef.current.videoHeight === 0) {
					console.log("å‹•ç”»ã‚µã‚¤ã‚ºãŒç„¡åŠ¹ã§ã™ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚");
					return;
				}
				
				// ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚µã‚¤ã‚ºã‚’å‹•ç”»ã‚µã‚¤ã‚ºã«åˆã‚ã›ã‚‹
				if (canvasRef.current) {
					canvasRef.current.width = videoRef.current.videoWidth;
					canvasRef.current.height = videoRef.current.videoHeight;
				}

				const hands = await model.estimateHands(videoRef.current);

				if (!canvasRef.current) return;
				const ctx = canvasRef.current.getContext("2d");
				if (!ctx) return;

				ctx.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);

				// æ¤œå‡ºã•ã‚ŒãŸå„æ‰‹ã«ã¤ã„ã¦å‡¦ç†
				for (let i = 0; i < hands.length; i++) {
					const hand = hands[i];
					const keypoints = hand.keypoints;
					
					// å„ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ã‚’æç”»
					for (let j = 0; j < keypoints.length; j++) {
						const { x, y } = keypoints[j];
						ctx.beginPath();
						ctx.arc(x, y, 5, 0, 3 * Math.PI);
						ctx.fillStyle = "aqua";
						ctx.fill();
					}
					
					// éª¨æ ¼ï¼ˆæŒ‡ã®æ¥ç¶šï¼‰ã‚’æç”»
					for (const [start, end] of connections) {
						const startPoint = keypoints[start];
						const endPoint = keypoints[end];
						
						if (startPoint && endPoint) {
							ctx.beginPath();
							ctx.moveTo(startPoint.x, startPoint.y);
							ctx.lineTo(endPoint.x, endPoint.y);
							ctx.strokeStyle = "yellow";
							ctx.lineWidth = 2;
							ctx.stroke();
						}
					}
					
					// æ‰‹ã®ç¨®é¡ï¼ˆå·¦/å³ï¼‰ã‚’è¡¨ç¤º
					const handedness = hand.handedness; // 'Left' ã¾ãŸã¯ 'Right'
					// ãƒ“ãƒ‡ã‚ªåè»¢ã‚’å‰Šé™¤ã—ãŸã®ã§ã€ãã®ã¾ã¾è¡¨ç¤º
					const handText = `${handedness} Hand`;
					ctx.font = "16px Arial";
					ctx.fillStyle = "white";
					
					// æ‰‹é¦–ã®ä½ç½®ã®è¿‘ãã«ãƒ†ã‚­ã‚¹ãƒˆã‚’è¡¨ç¤º
					const wrist = keypoints[0];
					if (wrist) {
						ctx.fillText(handText, wrist.x - 20, wrist.y - 10);
					}
				}
			} catch (error) {
				console.error("æ‰‹ã®æ¤œå‡ºã‚¨ãƒ©ãƒ¼:", error);
			}
		};

		const interval = setInterval(detect, 100); // 0.1ç§’ã”ã¨ã«æ¤œå‡º
		return () => clearInterval(interval);
	}, [model, videoRef, canvasRef, isVideoReady]);

	return {
		isLoading,
	}
};

const useFaceDetection = (
	videoRef: RefObject<HTMLVideoElement>,
	canvasRef: RefObject<HTMLCanvasElement>,
	isVideoReady: boolean,
) => {
	const [isLoading, setIsLoading] = useState(false);
	const [model, setModel] = useState<faceLandmarksDetection.FaceLandmarksDetector>();

	useEffect(() => {
		const loadFaceDetection = async () => {
			try {
				// TensorFlowãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®æº–å‚™ã‚’ç¢ºèª
				await tf.ready();
				
				const model = faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh;
				const detectorConfig = {
					runtime: 'tfjs',
					refineLandmarks: false,
					maxFaces: 1
				} as const;
				const detector = await faceLandmarksDetection.createDetector(
					model,
					detectorConfig
				);
				setModel(detector);
			} catch (error) {
				console.error("é¡”æ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼:", error);
			}
		};

		setIsLoading(true);
		loadFaceDetection().finally(() => {
			setIsLoading(false);
		});
	}, []);

	useEffect(() => {
		const detect = async () => {
			if (!model) return;
			if (!videoRef.current) return;
			if (!canvasRef.current) return;
			if (!isVideoReady) return; // å‹•ç”»ãŒæº–å‚™ã§ãã¦ã„ãªã‘ã‚Œã°æ¤œå‡ºã—ãªã„
			
			try {
				// å‹•ç”»ã®ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
				if (videoRef.current.videoWidth === 0 || videoRef.current.videoHeight === 0) {
					console.log("å‹•ç”»ã‚µã‚¤ã‚ºãŒç„¡åŠ¹ã§ã™ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚");
					return;
				}
				
				// ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚µã‚¤ã‚ºã‚’å‹•ç”»ã‚µã‚¤ã‚ºã«åˆã‚ã›ã‚‹
				canvasRef.current.width = videoRef.current.videoWidth;
				canvasRef.current.height = videoRef.current.videoHeight;
				
				const faces = await model.estimateFaces(videoRef.current);
				
				const ctx = canvasRef.current.getContext("2d");
				if (!ctx) return;

				ctx.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);

				for (let i = 0; i < faces.length; i++) {
					const face = faces[i];
					const keypoints = face.keypoints;
					
					for (let j = 0; j < keypoints.length; j++) {
						const { x, y } = keypoints[j];
						ctx.beginPath();
						ctx.arc(x, y, 2, 0, 3 * Math.PI);
						ctx.fillStyle = "red";
						ctx.fill();
					}
				}
			} catch (error) {
				console.error("é¡”ã®æ¤œå‡ºã‚¨ãƒ©ãƒ¼:", error);
			}
		};

		const interval = setInterval(detect, 100); // 0.1ç§’ã”ã¨ã«æ¤œå‡º
		return () => clearInterval(interval);
	}, [model, videoRef, canvasRef, isVideoReady]);

	return {
		isLoading,
	}
};

const usePoseDetection = (
	videoRef: RefObject<HTMLVideoElement>,
	canvasRef: RefObject<HTMLCanvasElement>,
	isVideoReady: boolean,
) => {
	const [isLoading, setIsLoading] = useState(false);
	const [model, setModel] = useState<poseDetection.PoseDetector>();

	useEffect(() => {
		const loadPoseDetection = async () => {
			try {
				// TensorFlowãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã®æº–å‚™ã‚’ç¢ºèª
				await tf.ready();
				
				const model = poseDetection.SupportedModels.MoveNet;
				// è¤‡æ•°äººæ¤œå‡ºç”¨ã®ãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®š
				const detector = await poseDetection.createDetector(
					model,
					{
						modelType: poseDetection.movenet.modelType.MULTIPOSE_LIGHTNING,
						enableSmoothing: true, // ã‚¹ãƒ ãƒ¼ã‚¸ãƒ³ã‚°ã‚’æœ‰åŠ¹åŒ–
					}
				);
				setModel(detector);
			} catch (error) {
				console.error("ãƒãƒ¼ã‚ºæ¤œå‡ºãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼:", error);
			}
		};

		setIsLoading(true);
		loadPoseDetection().finally(() => {
			setIsLoading(false);
		});
	}, []);

	useEffect(() => {
		// éª¨æ ¼ã®æ¥ç¶šå®šç¾©
		const connections = [
			// é¡”
			['nose', 'left_eye'],
			['nose', 'right_eye'],
			['left_eye', 'left_ear'],
			['right_eye', 'right_ear'],
			// ä¸ŠåŠèº«
			['left_shoulder', 'right_shoulder'],
			['left_shoulder', 'left_elbow'],
			['right_shoulder', 'right_elbow'],
			['left_elbow', 'left_wrist'],
			['right_elbow', 'right_wrist'],
			// ä¸‹åŠèº«
			['left_shoulder', 'left_hip'],
			['right_shoulder', 'right_hip'],
			['left_hip', 'right_hip'],
			['left_hip', 'left_knee'],
			['right_hip', 'right_knee'],
			['left_knee', 'left_ankle'],
			['right_knee', 'right_ankle'],
		];

		// å„ãƒãƒ¼ã‚ºã«ç•°ãªã‚‹è‰²ã‚’å‰²ã‚Šå½“ã¦ã‚‹ãŸã‚ã®é…åˆ—
		const colors = [
			{ point: "lime", line: "aqua" },      // 1äººç›®: è–„ç·‘ã¨æ°´è‰²
			{ point: "magenta", line: "yellow" },  // 2äººç›®: ãƒã‚¼ãƒ³ã‚¿ã¨é»„è‰²
			{ point: "orange", line: "red" },      // 3äººç›®: ã‚ªãƒ¬ãƒ³ã‚¸ã¨èµ¤
			{ point: "cyan", line: "blue" },       // 4äººç›®: ã‚·ã‚¢ãƒ³ã¨é’
			{ point: "white", line: "green" }      // 5äººç›®: ç™½ã¨ç·‘
		];

		const detect = async () => {
			if (!model) return;
			if (!videoRef.current) return;
			if (!canvasRef.current) return;
			if (!isVideoReady) return; // å‹•ç”»ãŒæº–å‚™ã§ãã¦ã„ãªã‘ã‚Œã°æ¤œå‡ºã—ãªã„
			
			try {
				// å‹•ç”»ã®ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
				if (videoRef.current.videoWidth === 0 || videoRef.current.videoHeight === 0) {
					console.log("å‹•ç”»ã‚µã‚¤ã‚ºãŒç„¡åŠ¹ã§ã™ã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚");
					return;
				}
				
				// ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚µã‚¤ã‚ºã‚’å‹•ç”»ã‚µã‚¤ã‚ºã«åˆã‚ã›ã‚‹
				canvasRef.current.width = videoRef.current.videoWidth;
				canvasRef.current.height = videoRef.current.videoHeight;
				
				const poses = await model.estimatePoses(videoRef.current);
				
				const ctx = canvasRef.current.getContext("2d");
				if (!ctx) return;

				ctx.clearRect(0, 0, canvasRef.current.width, canvasRef.current.height);

				// æ¤œå‡ºã•ã‚ŒãŸäººæ•°ã‚’è¡¨ç¤º
				ctx.font = "16px Arial";
				ctx.fillStyle = "white";
				ctx.fillText(`æ¤œå‡ºã•ã‚ŒãŸäººæ•°: ${poses.length}äºº`, 20, 30);

				// å„æ¤œå‡ºã•ã‚ŒãŸãƒãƒ¼ã‚ºã‚’å‡¦ç†
				for (let i = 0; i < poses.length; i++) {
					const pose = poses[i];
					const keypoints = pose.keypoints;
					const colorSet = colors[i % colors.length]; // äººæ•°ã«å¿œã˜ã¦è‰²ã‚’å¾ªç’°ä½¿ç”¨

					// ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã®æç”»
					for (const keypoint of keypoints) {
						if (keypoint.score && keypoint.score > 0.3) { // ä¿¡é ¼åº¦ãŒ30%ä»¥ä¸Šã®ãƒã‚¤ãƒ³ãƒˆã®ã¿æç”»
							const { x, y } = keypoint;
							ctx.beginPath();
							ctx.arc(x, y, 6, 0, 3 * Math.PI);
							ctx.fillStyle = colorSet.point;
							ctx.fill();
						}
					}
					
					// éª¨æ ¼ã®ç·šã‚’æç”»
					ctx.lineWidth = 3;
					ctx.strokeStyle = colorSet.line;
					
					for (const [from, to] of connections) {
						const fromPoint = keypoints.find(kp => kp.name === from);
						const toPoint = keypoints.find(kp => kp.name === to);
						
						if (fromPoint && toPoint && 
							fromPoint.score && toPoint.score && 
							fromPoint.score > 0.3 && toPoint.score > 0.3) {
							ctx.beginPath();
							ctx.moveTo(fromPoint.x, fromPoint.y);
							ctx.lineTo(toPoint.x, toPoint.y);
							ctx.stroke();
						}
					}
					
					// ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ã®è¡¨ç¤º
					ctx.font = "16px Arial";
					ctx.fillStyle = colorSet.point;
					const score = Math.round((pose.score || 0) * 100) / 100;
					// å„äººã®ã‚¹ã‚³ã‚¢ã‚’è¡¨ç¤ºï¼ˆå°‘ã—ãšã¤ä½ç½®ã‚’ãšã‚‰ã™ï¼‰
					ctx.fillText(`ID ${i+1} ä¿¡é ¼åº¦: ${score}`, 20, 60 + i * 25);
				}
			} catch (error) {
				console.error("ãƒãƒ¼ã‚ºæ¤œå‡ºã‚¨ãƒ©ãƒ¼:", error);
			}
		};

		const interval = setInterval(detect, 100); // 0.1ç§’ã”ã¨ã«æ¤œå‡º
		return () => clearInterval(interval);
	}, [model, videoRef, canvasRef, isVideoReady]);

	return {
		isLoading,
	}
};

function App() {
	const videoRef = useRef<HTMLVideoElement>(null);
	const canvasRef = useRef<HTMLCanvasElement>(null);
	const [videoFile, setVideoFile] = useState<File | null>(null);
	const { isAllowed, isVideoReady } = useVideo(videoRef, videoFile);
	const [activeTab, setActiveTab] = useState<TabType>("face");
	
	const { isLoading: isHandLoading } = useHandpose(
		activeTab === "hand" ? videoRef : { current: null },
		activeTab === "hand" ? canvasRef : { current: null },
		isVideoReady
	);
	
	const { isLoading: isFaceLoading } = useFaceDetection(
		activeTab === "face" ? videoRef : { current: null },
		activeTab === "face" ? canvasRef : { current: null },
		isVideoReady
	);

	const { isLoading: isPoseLoading } = usePoseDetection(
		activeTab === "pose" ? videoRef : { current: null },
		activeTab === "pose" ? canvasRef : { current: null },
		isVideoReady
	);

	const isLoading = 
		activeTab === "hand" ? isHandLoading : 
		activeTab === "face" ? isFaceLoading : 
		isPoseLoading;

	// ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠãƒãƒ³ãƒ‰ãƒ©ãƒ¼
	const handleFileChange = (event: React.ChangeEvent<HTMLInputElement>) => {
		const files = event.target.files;
		if (files && files.length > 0) {
			const file = files[0];
			// ãƒ•ã‚¡ã‚¤ãƒ«ãŒãƒ“ãƒ‡ã‚ªã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
			if (file.type.startsWith('video/')) {
				setVideoFile(file);
			} else {
				alert('å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„');
			}
		}
	};

	// ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠã‚’ãƒªã‚»ãƒƒãƒˆ
	const resetVideo = () => {
		setVideoFile(null);
	};

	return (
		<div className="app-container" style={{
			width: "100vw",
			height: "100vh",
			margin: 0,
			padding: 0,
			overflow: "hidden",
			position: "relative",
			fontFamily: "Arial, sans-serif",
			backgroundColor: "#000",
		}}>
			{/* ãƒ“ãƒ‡ã‚ªã¨ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚’å…¨ç”»é¢è¡¨ç¤º */}
			<div
				style={{
					position: "absolute",
					top: 0,
					left: 0,
					width: "100%",
					height: "100%",
					zIndex: 1,
				}}
			>
				<video
					style={{
						position: "absolute",
						top: 0,
						left: 0,
						width: "100%",
						height: "100%",
						objectFit: "cover",
					}}
					ref={videoRef}
					width="640"
					height="480"
					autoPlay
					playsInline
				/>
				<canvas
					style={{
						position: "absolute",
						top: 0,
						left: 0,
						width: "100%",
						height: "100%",
						objectFit: "cover",
						pointerEvents: "none", // ã‚­ãƒ£ãƒ³ãƒã‚¹ã‚’æ“ä½œä¸å¯ã«
					}}
					ref={canvasRef}
				/>
			</div>

			{/* ãƒ•ãƒ­ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¿ã‚¤ãƒˆãƒ« */}
			<div style={{
				position: "absolute",
				top: "20px",
				left: "20px",
				zIndex: 10,
				color: "white",
				textShadow: "0 2px 4px rgba(0,0,0,0.5)",
			}}>
				<h1 style={{
					margin: "0 0 4px 0",
					fontSize: "24px",
					fontWeight: "bold",
				}}>AIå§¿å‹¢æ¤œå‡ºãƒ‡ãƒ¢</h1>
				<p style={{
					margin: 0,
					fontSize: "14px",
					opacity: 0.8,
				}}>TensorFlow.jsã‚’ä½¿ã£ãŸæ‰‹ã¨é¡”ã¨ãƒãƒ¼ã‚ºã®æ¤œå‡º</p>
			</div>

			{/* ãƒ•ãƒ­ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¿ãƒ–åˆ‡ã‚Šæ›¿ãˆ */}
			<div style={{ 
				position: "absolute",
				top: "20px",
				right: "20px",
				zIndex: 10,
				display: "flex",
				gap: "12px",
			}}>
				<button 
					onClick={() => setActiveTab("hand")}
					style={{ 
						padding: "8px 16px", 
						backgroundColor: activeTab === "hand" ? "rgba(52, 152, 219, 0.9)" : "rgba(0, 0, 0, 0.6)",
						color: "white",
						border: "none",
						borderRadius: "30px",
						cursor: "pointer",
						backdropFilter: "blur(4px)",
						boxShadow: "0 2px 8px rgba(0, 0, 0, 0.3)",
						display: "flex",
						alignItems: "center",
						fontWeight: activeTab === "hand" ? "bold" : "normal",
						transition: "all 0.3s ease",
					}}
				>
					<span style={{ marginRight: "6px" }}>âœ‹</span> æ‰‹ã®æ¤œå‡º
				</button>
				<button 
					onClick={() => setActiveTab("face")}
					style={{ 
						padding: "8px 16px", 
						backgroundColor: activeTab === "face" ? "rgba(52, 152, 219, 0.9)" : "rgba(0, 0, 0, 0.6)",
						color: "white",
						border: "none",
						borderRadius: "30px",
						cursor: "pointer",
						backdropFilter: "blur(4px)",
						boxShadow: "0 2px 8px rgba(0, 0, 0, 0.3)",
						display: "flex",
						alignItems: "center",
						fontWeight: activeTab === "face" ? "bold" : "normal",
						transition: "all 0.3s ease",
					}}
				>
					<span style={{ marginRight: "6px" }}>ğŸ˜Š</span> é¡”ã®æ¤œå‡º
				</button>
				<button 
					onClick={() => setActiveTab("pose")}
					style={{ 
						padding: "8px 16px", 
						backgroundColor: activeTab === "pose" ? "rgba(52, 152, 219, 0.9)" : "rgba(0, 0, 0, 0.6)",
						color: "white",
						border: "none",
						borderRadius: "30px",
						cursor: "pointer",
						backdropFilter: "blur(4px)",
						boxShadow: "0 2px 8px rgba(0, 0, 0, 0.3)",
						display: "flex",
						alignItems: "center",
						fontWeight: activeTab === "pose" ? "bold" : "normal",
						transition: "all 0.3s ease",
					}}
				>
					<span style={{ marginRight: "6px" }}>ğŸƒ</span> ãƒãƒ¼ã‚ºæ¤œå‡º
				</button>
			</div>

			{/* ãƒ•ãƒ­ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ãƒ’ãƒ³ãƒˆ */}
			<div style={{ 
				position: "absolute",
				bottom: "20px",
				left: "50%",
				transform: "translateX(-50%)",
				zIndex: 10,
				padding: "10px 20px", 
				backgroundColor: "rgba(0, 0, 0, 0.6)",
				color: "white",
				borderRadius: "30px",
				backdropFilter: "blur(4px)",
				boxShadow: "0 2px 8px rgba(0, 0, 0, 0.3)",
				maxWidth: "80%",
				textAlign: "center",
			}}>
				<p style={{ margin: "0" }}>
					<strong>ãƒ’ãƒ³ãƒˆ:</strong> {
						activeTab === "hand" ? "ä¸¡æ‰‹ã‚’ç”»é¢å†…ã«è¡¨ç¤ºã™ã‚‹ã¨ã€é–¢ç¯€ã¨éª¨æ ¼ãŒæ¤œå‡ºã•ã‚Œã¾ã™ã€‚" : 
						activeTab === "face" ? "é¡”ã‚’ç”»é¢å†…ã«è¡¨ç¤ºã™ã‚‹ã¨ã€é¡”ã®ãƒ©ãƒ³ãƒ‰ãƒãƒ¼ã‚¯ãŒæ¤œå‡ºã•ã‚Œã¾ã™ã€‚" :
						"è¤‡æ•°äººã®å§¿å‹¢ã‚‚æ¤œå‡ºã§ãã¾ã™ã€‚ãã‚Œãã‚Œç•°ãªã‚‹è‰²ã§è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚"
					}
				</p>
			</div>

			{/* ãƒ•ã‚¡ã‚¤ãƒ«å…¥åŠ›UI */}
			<div style={{ 
				position: "absolute",
				bottom: "80px",
				left: "50%",
				transform: "translateX(-50%)",
				zIndex: 10,
				padding: "10px 20px", 
				backgroundColor: "rgba(0, 0, 0, 0.6)",
				color: "white",
				borderRadius: "30px",
				backdropFilter: "blur(4px)",
				boxShadow: "0 2px 8px rgba(0, 0, 0, 0.3)",
				display: "flex",
				alignItems: "center",
				gap: "10px",
			}}>
				{videoFile ? (
					<>
						<span>{videoFile.name}</span>
						<button
							onClick={resetVideo}
							style={{
								backgroundColor: "rgba(220, 53, 69, 0.7)",
								color: "white",
								border: "none",
								borderRadius: "20px",
								padding: "6px 12px",
								cursor: "pointer",
								display: "flex",
								alignItems: "center",
								gap: "5px",
							}}
						>
							<span>âœ–</span> ã‚­ãƒ£ãƒ³ã‚»ãƒ«
						</button>
					</>
				) : (
					<>
						<label
							htmlFor="video-upload"
							style={{
								backgroundColor: "rgba(52, 152, 219, 0.7)",
								color: "white",
								borderRadius: "20px",
								padding: "6px 12px",
								cursor: "pointer",
								display: "flex",
								alignItems: "center",
								gap: "5px",
							}}
						>
							<span>ğŸ“</span> å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ
						</label>
						<input
							id="video-upload"
							type="file"
							accept="video/*"
							onChange={handleFileChange}
							style={{ display: "none" }}
						/>
					</>
				)}
			</div>

			{/* å‹•ç”»èª­ã¿è¾¼ã¿çŠ¶æ…‹ã®è¡¨ç¤º */}
			{videoFile && !isVideoReady && (
				<div style={{
					position: "absolute",
					top: "50%",
					left: "50%",
					transform: "translate(-50%, -50%)",
					zIndex: 20,
					backgroundColor: "rgba(0, 0, 0, 0.7)",
					color: "white",
					padding: "20px 30px",
					borderRadius: "8px",
					backdropFilter: "blur(10px)",
					boxShadow: "0 4px 12px rgba(0, 0, 0, 0.3)",
					textAlign: "center",
					display: "flex",
					flexDirection: "column",
					alignItems: "center",
					justifyContent: "center",
					minWidth: "200px",
				}}>
					<div style={{
						border: "3px solid rgba(255, 255, 255, 0.1)",
						borderTop: "3px solid #fff",
						borderRadius: "50%",
						width: "30px",
						height: "30px",
						animation: "spin 1s linear infinite",
						marginBottom: "12px",
					}} />
					<p style={{ margin: "0", fontWeight: "bold" }}>å‹•ç”»ã‚’èª­ã¿è¾¼ã¿ä¸­...</p>
				</div>
			)}

			{/* ã‚«ãƒ¡ãƒ©è¨±å¯é€šçŸ¥ */}
			{!isAllowed && (
				<div style={{
					position: "absolute",
					top: "50%",
					left: "50%",
					transform: "translate(-50%, -50%)",
					zIndex: 20,
					backgroundColor: "rgba(220, 53, 69, 0.9)",
					color: "white",
					padding: "20px 30px",
					borderRadius: "8px",
					backdropFilter: "blur(10px)",
					boxShadow: "0 4px 12px rgba(0, 0, 0, 0.3)",
					textAlign: "center",
					minWidth: "300px",
				}}>
					<div style={{ fontSize: "32px", marginBottom: "10px" }}>ğŸ“·</div>
					<p style={{ margin: "0", fontWeight: "bold", fontSize: "16px" }}>ã‚«ãƒ¡ãƒ©ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒå¿…è¦ã§ã™</p>
					<p style={{ margin: "8px 0 0 0", fontSize: "14px" }}>ã“ã®ã‚¢ãƒ—ãƒªã¯ã‚«ãƒ¡ãƒ©ã‚’ä½¿ç”¨ã—ã¦æ‰‹ã¨é¡”ã‚’æ¤œå‡ºã—ã¾ã™</p>
				</div>
			)}
			
			{/* ãƒ­ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¡¨ç¤º */}
			{isLoading && (
				<div style={{
					position: "absolute",
					top: "50%",
					left: "50%",
					transform: "translate(-50%, -50%)",
					zIndex: 20,
					backgroundColor: "rgba(0, 0, 0, 0.7)",
					color: "white",
					padding: "20px 30px",
					borderRadius: "8px",
					backdropFilter: "blur(10px)",
					boxShadow: "0 4px 12px rgba(0, 0, 0, 0.3)",
					textAlign: "center",
					display: "flex",
					flexDirection: "column",
					alignItems: "center",
					justifyContent: "center",
					minWidth: "200px",
				}}>
					<div style={{
						border: "3px solid rgba(255, 255, 255, 0.1)",
						borderTop: "3px solid #fff",
						borderRadius: "50%",
						width: "30px",
						height: "30px",
						animation: "spin 1s linear infinite",
						marginBottom: "12px",
					}} />
					<p style={{ margin: "0", fontWeight: "bold" }}>ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­...</p>
				</div>
			)}
			
			<style>{`
				@keyframes spin {
					0% { transform: rotate(0deg); }
					100% { transform: rotate(360deg); }
				}
				body {
					margin: 0;
					padding: 0;
					overflow: hidden;
				}
				#root {
					max-width: none !important;
					width: 100vw;
					height: 100vh;
					margin: 0;
					padding: 0;
					overflow: hidden;
				}
			`}</style>
		</div>
	);
}

export default App;
